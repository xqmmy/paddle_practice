{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 作业\n",
    "\n",
    "- 补全程序中的代码，理解其含义，并跑通整个项目；\n",
    "- 报名参加[千言数据集：信息抽取比赛](https://aistudio.baidu.com/aistudio/competition/detail/46)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 基于预训练模型完成实体关系抽取\n",
    "\n",
    "信息抽取旨在从非结构化自然语言文本中提取结构化知识，如实体、关系、事件等。对于给定的自然语言句子，根据预先定义的schema集合，抽取出所有满足schema约束的SPO三元组。\n",
    "\n",
    "例如，「妻子」关系的schema定义为：      \n",
    "{      \n",
    "    S_TYPE: 人物,        \n",
    "    P: 妻子,      \n",
    "    O_TYPE: {      \n",
    "        @value: 人物       \n",
    "    }       \n",
    "}        \n",
    "\n",
    "该示例展示了如何使用PaddleNLP快速完成实体关系抽取，参与[千言信息抽取-关系抽取比赛](https://aistudio.baidu.com/aistudio/competition/detail/46)打榜。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirror.baidu.com/pypi/simple/\n",
      "Requirement already up-to-date: paddlenlp in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (2.0.3)\n",
      "Requirement already satisfied, skipping upgrade: multiprocess in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.70.11.1)\n",
      "Requirement already satisfied, skipping upgrade: colorlog in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (4.1.0)\n",
      "Requirement already satisfied, skipping upgrade: jieba in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.42.1)\n",
      "Requirement already satisfied, skipping upgrade: colorama in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.4.4)\n",
      "Requirement already satisfied, skipping upgrade: h5py in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (2.9.0)\n",
      "Requirement already satisfied, skipping upgrade: seqeval in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (1.2.2)\n",
      "Requirement already satisfied, skipping upgrade: visualdl in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (2.1.1)\n",
      "Requirement already satisfied, skipping upgrade: dill>=0.3.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from multiprocess->paddlenlp) (0.3.3)\n",
      "Requirement already satisfied, skipping upgrade: six in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from h5py->paddlenlp) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.7 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from h5py->paddlenlp) (1.20.3)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn>=0.21.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from seqeval->paddlenlp) (0.24.2)\n",
      "Requirement already satisfied, skipping upgrade: flask>=1.1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: flake8>=3.7.9 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (3.8.2)\n",
      "Requirement already satisfied, skipping upgrade: Flask-Babel>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: Pillow>=7.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (7.1.2)\n",
      "Requirement already satisfied, skipping upgrade: requests in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: pre-commit in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.21.0)\n",
      "Requirement already satisfied, skipping upgrade: bce-python-sdk in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (0.8.53)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.11.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (3.14.0)\n",
      "Requirement already satisfied, skipping upgrade: shellcheck-py in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (0.7.1.1)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (0.14.1)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (1.6.3)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: Werkzeug>=0.15 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (0.16.0)\n",
      "Requirement already satisfied, skipping upgrade: click>=5.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (7.0)\n",
      "Requirement already satisfied, skipping upgrade: itsdangerous>=0.24 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: Jinja2>=2.10.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (2.10.1)\n",
      "Requirement already satisfied, skipping upgrade: pycodestyle<2.7.0,>=2.6.0a1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl->paddlenlp) (2.6.0)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl->paddlenlp) (0.23)\n",
      "Requirement already satisfied, skipping upgrade: pyflakes<2.3.0,>=2.2.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl->paddlenlp) (2.2.0)\n",
      "Requirement already satisfied, skipping upgrade: mccabe<0.7.0,>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl->paddlenlp) (0.6.1)\n",
      "Requirement already satisfied, skipping upgrade: Babel>=2.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl->paddlenlp) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: pytz in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl->paddlenlp) (2019.3)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl->paddlenlp) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl->paddlenlp) (1.25.6)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl->paddlenlp) (2019.9.11)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl->paddlenlp) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: identify>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (1.4.10)\n",
      "Requirement already satisfied, skipping upgrade: aspy.yaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: pyyaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (5.1.2)\n",
      "Requirement already satisfied, skipping upgrade: toml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: cfgv>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (2.0.1)\n",
      "Requirement already satisfied, skipping upgrade: virtualenv>=15.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (16.7.9)\n",
      "Requirement already satisfied, skipping upgrade: nodeenv>=0.11.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (1.3.4)\n",
      "Requirement already satisfied, skipping upgrade: future>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl->paddlenlp) (0.18.0)\n",
      "Requirement already satisfied, skipping upgrade: pycryptodome>=3.8.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl->paddlenlp) (3.9.9)\n",
      "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Jinja2>=2.10.1->flask>=1.1.1->visualdl->paddlenlp) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->flake8>=3.7.9->visualdl->paddlenlp) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: more-itertools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from zipp>=0.5->importlib-metadata; python_version < \"3.8\"->flake8>=3.7.9->visualdl->paddlenlp) (7.2.0)\n",
      "/home/aistudio/relation_extraction\n"
     ]
    }
   ],
   "source": [
    "# 安装paddlenlp最新版本\n",
    "!pip install --upgrade paddlenlp\n",
    "\n",
    "%cd relation_extraction/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 关系抽取介绍\n",
    "\n",
    "针对 DuIE2.0 任务中多条、交叠SPO这一抽取目标，比赛对标准的 'BIO' 标注进行了扩展。\n",
    "对于每个 token，根据其在实体span中的位置（包括B、I、O三种），我们为其打上三类标签，并且根据其所参与构建的predicate种类，将 B 标签进一步区分。给定 schema 集合，对于 N 种不同 predicate，以及头实体/尾实体两种情况，我们设计对应的共 2*N 种 B 标签，再合并 I 和 O 标签，故每个 token 一共有 (2*N+2) 个标签，如下图所示。\n",
    "\n",
    "\n",
    "<div align=\"center\">\n",
    "<img src=\"https://ai-studio-static-online.cdn.bcebos.com/f984664777b241a9b43ef843c9b752f33906c8916bc146a69f7270b5858bee63\" width=\"500\" height=\"400\" alt=\"标注策略\" align=center />\n",
    "</div>\n",
    "\n",
    "### 评价方法\n",
    "\n",
    "对测试集上参评系统输出的SPO结果和人工标注的SPO结果进行精准匹配，采用F1值作为评价指标。注意，对于复杂O值类型的SPO，必须所有槽位都精确匹配才认为该SPO抽取正确。针对部分文本中存在实体别名的问题，使用百度知识图谱的别名词典来辅助评测。F1值的计算方式如下：\n",
    "\n",
    "F1 = (2 * P * R) / (P + R)，其中\n",
    "\n",
    "- P = 测试集所有句子中预测正确的SPO个数 / 测试集所有句子中预测出的SPO个数\n",
    "- R = 测试集所有句子中预测正确的SPO个数 / 测试集所有句子中人工标注的SPO个数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Step1：构建模型\n",
    "\n",
    "该任务可以看作一个序列标注任务，所以基线模型采用的是ERNIE序列标注模型。\n",
    "\n",
    "**PaddleNLP提供了ERNIE预训练模型常用序列标注模型，可以通过指定模型名字完成一键加载。PaddleNLP为了方便用户处理数据，内置了对于各个预训练模型对应的Tokenizer，可以完成文本token化，转token ID，文本长度截断等操作。**\n",
    "\n",
    "文本数据处理直接调用tokenizer即可输出模型所需输入数据。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-06-18 09:11:16,468] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/ernie-1.0/ernie_v1_chn_base.pdparams\n",
      "[2021-06-18 09:11:18,350] [    INFO] - Found /home/aistudio/.paddlenlp/models/ernie-1.0/vocab.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from paddlenlp.transformers import ErnieForTokenClassification, ErnieTokenizer\n",
    "import sys\n",
    "\n",
    "label_map_path = os.path.join('data', \"predicate2id.json\")\n",
    "\n",
    "if not (os.path.exists(label_map_path) and os.path.isfile(label_map_path)):\n",
    "    sys.exit(\"{} dose not exists or is not a file.\".format(label_map_path))\n",
    "with open(label_map_path, 'r', encoding='utf8') as fp:\n",
    "    label_map = json.load(fp)\n",
    "    \n",
    "num_classes = (len(label_map.keys()) - 2) * 2 + 2\n",
    "\n",
    "# 补齐代码，理解TokenClassification接口含义，理解关系抽取标注体系和类别数由来\n",
    "# model = ErnieForTokenClassification.from_pretrained(\"ernie-1.0\", num_classes=num_classes)\n",
    "model = ErnieForTokenClassification.from_pretrained(\"ernie-1.0\", num_classes=(len(label_map) - 2) * 2 + 2)\n",
    "tokenizer = ErnieTokenizer.from_pretrained(\"ernie-1.0\")\n",
    "\n",
    "inputs = tokenizer(text=\"请输入测试样例\", max_seq_len=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Step2：加载并处理数据\n",
    "\n",
    "\n",
    "从比赛官网下载数据集，解压存放于data/目录下并重命名为train_data.json, dev_data.json, test_data.json.\n",
    "\n",
    "我们可以加载自定义数据集。通过继承[`paddle.io.Dataset`](https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/io/Dataset_cn.html#dataset)，自定义实现`__getitem__` 和 `__len__`两个方法。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from typing import Optional, List, Union, Dict\n",
    "\n",
    "import numpy as np\n",
    "import paddle\n",
    "from tqdm import tqdm\n",
    "from paddlenlp.utils.log import logger\n",
    "\n",
    "from data_loader import parse_label, DataCollator, convert_example_to_feature\n",
    "from extract_chinese_and_punct import ChineseAndPunctuationExtractor\n",
    "\n",
    "\n",
    "class DuIEDataset(paddle.io.Dataset):\n",
    "    \"\"\"\n",
    "    Dataset of DuIE.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_ids: List[Union[List[int], np.ndarray]],\n",
    "            seq_lens: List[Union[List[int], np.ndarray]],\n",
    "            tok_to_orig_start_index: List[Union[List[int], np.ndarray]],\n",
    "            tok_to_orig_end_index: List[Union[List[int], np.ndarray]],\n",
    "            labels: List[Union[List[int], np.ndarray, List[str], List[Dict]]]):\n",
    "        super(DuIEDataset, self).__init__()\n",
    "\n",
    "        self.input_ids = input_ids\n",
    "        self.seq_lens = seq_lens\n",
    "        self.tok_to_orig_start_index = tok_to_orig_start_index\n",
    "        self.tok_to_orig_end_index = tok_to_orig_end_index\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        if isinstance(self.input_ids, np.ndarray):\n",
    "            return self.input_ids.shape[0]\n",
    "        else:\n",
    "            return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return {\n",
    "            \"input_ids\": np.array(self.input_ids[item]),\n",
    "            \"seq_lens\": np.array(self.seq_lens[item]),\n",
    "            \"tok_to_orig_start_index\":\n",
    "            np.array(self.tok_to_orig_start_index[item]),\n",
    "            \"tok_to_orig_end_index\": np.array(self.tok_to_orig_end_index[item]),\n",
    "            # If model inputs is generated in `collate_fn`, delete the data type casting.\n",
    "            \"labels\": np.array(\n",
    "                self.labels[item], dtype=np.float32),\n",
    "        }\n",
    "\n",
    "    @classmethod\n",
    "    def from_file(cls,\n",
    "                  file_path: Union[str, os.PathLike],\n",
    "                  tokenizer: ErnieTokenizer,\n",
    "                  max_length: Optional[int]=512,\n",
    "                  pad_to_max_length: Optional[bool]=None):\n",
    "        assert os.path.exists(file_path) and os.path.isfile(\n",
    "            file_path), f\"{file_path} dose not exists or is not a file.\"\n",
    "        label_map_path = os.path.join(\n",
    "            os.path.dirname(file_path), \"predicate2id.json\")\n",
    "        assert os.path.exists(label_map_path) and os.path.isfile(\n",
    "            label_map_path\n",
    "        ), f\"{label_map_path} dose not exists or is not a file.\"\n",
    "        with open(label_map_path, 'r', encoding='utf8') as fp:\n",
    "            label_map = json.load(fp)\n",
    "        chineseandpunctuationextractor = ChineseAndPunctuationExtractor()\n",
    "\n",
    "        input_ids, seq_lens, tok_to_orig_start_index, tok_to_orig_end_index, labels = (\n",
    "            [] for _ in range(5))\n",
    "        dataset_scale = sum(1 for line in open(file_path, 'r'))\n",
    "        logger.info(\"Preprocessing data, loaded from %s\" % file_path)\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as fp:\n",
    "            lines = fp.readlines()\n",
    "            for line in tqdm(lines):\n",
    "                example = json.loads(line)\n",
    "                input_feature = convert_example_to_feature(\n",
    "                    example, tokenizer, chineseandpunctuationextractor,\n",
    "                    label_map, max_length, pad_to_max_length)\n",
    "                input_ids.append(input_feature.input_ids)\n",
    "                seq_lens.append(input_feature.seq_len)\n",
    "                tok_to_orig_start_index.append(\n",
    "                    input_feature.tok_to_orig_start_index)\n",
    "                tok_to_orig_end_index.append(\n",
    "                    input_feature.tok_to_orig_end_index)\n",
    "                labels.append(input_feature.labels)\n",
    "\n",
    "        return cls(input_ids, seq_lens, tok_to_orig_start_index,\n",
    "                   tok_to_orig_end_index, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-06-18 07:44:56,807] [    INFO] - Preprocessing data, loaded from data/train.json\n",
      "100%|██████████| 171293/171293 [05:15<00:00, 543.75it/s]\n",
      "[2021-06-18 07:50:12,267] [    INFO] - Preprocessing data, loaded from data/dev.json\n",
      "100%|██████████| 20674/20674 [00:37<00:00, 547.66it/s]\n"
     ]
    }
   ],
   "source": [
    "data_path = 'data'\n",
    "batch_size = 32\n",
    "max_seq_length = 128\n",
    "\n",
    "train_file_path = os.path.join(data_path, 'train.json')\n",
    "train_dataset = DuIEDataset.from_file(\n",
    "    train_file_path, tokenizer, max_seq_length, True)\n",
    "train_batch_sampler = paddle.io.BatchSampler(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "collator = DataCollator()\n",
    "train_data_loader = paddle.io.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_sampler=train_batch_sampler,\n",
    "    collate_fn=collator)\n",
    "\n",
    "eval_file_path = os.path.join(data_path, 'dev.json')\n",
    "test_dataset = DuIEDataset.from_file(\n",
    "    eval_file_path, tokenizer, max_seq_length, True)\n",
    "test_batch_sampler = paddle.io.BatchSampler(\n",
    "    test_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "test_data_loader = paddle.io.DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_sampler=test_batch_sampler,\n",
    "    collate_fn=collator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Step3：定义损失函数和优化器，开始训练\n",
    "\n",
    "我们选择均方误差作为损失函数，使用[`paddle.optimizer.AdamW`](https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/optimizer/adamw/AdamW_cn.html#adamw)作为优化器。\n",
    "\n",
    "\n",
    "\n",
    "在训练过程中，模型保存在当前目录checkpoints文件夹下。同时在训练的同时使用官方评测脚本进行评估，输出P/R/F1指标。\n",
    "在验证集上F1可以达到69.42。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import paddle.nn as nn\n",
    "\n",
    "class BCELossForDuIE(nn.Layer):\n",
    "    def __init__(self, ):\n",
    "        super(BCELossForDuIE, self).__init__()\n",
    "        self.criterion = nn.BCEWithLogitsLoss(reduction='none')\n",
    "\n",
    "    def forward(self, logits, labels, mask):\n",
    "        loss = self.criterion(logits, labels)\n",
    "        mask = paddle.cast(mask, 'float32')\n",
    "        loss = loss * mask.unsqueeze(-1)\n",
    "        loss = paddle.sum(loss.mean(axis=2), axis=1) / paddle.sum(mask, axis=1)\n",
    "        loss = loss.mean()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils import write_prediction_results, get_precision_recall_f1, decoding\n",
    "\n",
    "@paddle.no_grad()\n",
    "def evaluate(model, criterion, data_loader, file_path, mode):\n",
    "    \"\"\"\n",
    "    mode eval:\n",
    "    eval on development set and compute P/R/F1, called between training.\n",
    "    mode predict:\n",
    "    eval on development / test set, then write predictions to \\\n",
    "        predict_test.json and predict_test.json.zip \\\n",
    "        under /home/aistudio/relation_extraction/data dir for later submission or evaluation.\n",
    "    \"\"\"\n",
    "    example_all = []\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as fp:\n",
    "        for line in fp:\n",
    "            example_all.append(json.loads(line))\n",
    "    id2spo_path = os.path.join(os.path.dirname(file_path), \"id2spo.json\")\n",
    "    with open(id2spo_path, 'r', encoding='utf8') as fp:\n",
    "        id2spo = json.load(fp)\n",
    "\n",
    "    model.eval()\n",
    "    loss_all = 0\n",
    "    eval_steps = 0\n",
    "    formatted_outputs = []\n",
    "    current_idx = 0\n",
    "    for batch in tqdm(data_loader, total=len(data_loader)):\n",
    "        eval_steps += 1\n",
    "        input_ids, seq_len, tok_to_orig_start_index, tok_to_orig_end_index, labels = batch\n",
    "        logits = model(input_ids=input_ids)\n",
    "        mask = (input_ids != 0).logical_and((input_ids != 1)).logical_and((input_ids != 2))\n",
    "        loss = criterion(logits, labels, mask)\n",
    "        loss_all += loss.numpy().item()\n",
    "        probs = F.sigmoid(logits)\n",
    "        logits_batch = probs.numpy()\n",
    "        seq_len_batch = seq_len.numpy()\n",
    "        tok_to_orig_start_index_batch = tok_to_orig_start_index.numpy()\n",
    "        tok_to_orig_end_index_batch = tok_to_orig_end_index.numpy()\n",
    "        formatted_outputs.extend(decoding(example_all[current_idx: current_idx+len(logits)],\n",
    "                                          id2spo,\n",
    "                                          logits_batch,\n",
    "                                          seq_len_batch,\n",
    "                                          tok_to_orig_start_index_batch,\n",
    "                                          tok_to_orig_end_index_batch))\n",
    "        current_idx = current_idx+len(logits)\n",
    "    loss_avg = loss_all / eval_steps\n",
    "    print(\"eval loss: %f\" % (loss_avg))\n",
    "\n",
    "    if mode == \"predict\":\n",
    "        predict_file_path = os.path.join(\"/home/aistudio/relation_extraction/data\", 'predictions.json')\n",
    "    else:\n",
    "        predict_file_path = os.path.join(\"/home/aistudio/relation_extraction/data\", 'predict_eval.json')\n",
    "\n",
    "    predict_zipfile_path = write_prediction_results(formatted_outputs,\n",
    "                                                    predict_file_path)\n",
    "\n",
    "    if mode == \"eval\":\n",
    "        precision, recall, f1 = get_precision_recall_f1(file_path,\n",
    "                                                        predict_zipfile_path)\n",
    "        os.system('rm {} {}'.format(predict_file_path, predict_zipfile_path))\n",
    "        return precision, recall, f1\n",
    "    elif mode != \"predict\":\n",
    "        raise Exception(\"wrong mode for eval func\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from paddlenlp.transformers import LinearDecayWithWarmup\n",
    "\n",
    "learning_rate = 2e-5\n",
    "num_train_epochs = 5\n",
    "warmup_ratio = 0.06\n",
    "\n",
    "criterion = BCELossForDuIE()\n",
    "# Defines learning rate strategy.\n",
    "steps_by_epoch = len(train_data_loader)\n",
    "num_training_steps = steps_by_epoch * num_train_epochs\n",
    "lr_scheduler = LinearDecayWithWarmup(learning_rate, num_training_steps, warmup_ratio)\n",
    "optimizer = paddle.optimizer.AdamW(\n",
    "    learning_rate=lr_scheduler,\n",
    "    parameters=model.parameters(),\n",
    "    apply_decay_param_fun=lambda x: x in [\n",
    "        p.name for n, p in model.named_parameters()\n",
    "        if not any(nd in n for nd in [\"bias\", \"norm\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘checkpoints’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "# 模型参数保存路径\n",
    "!mkdir checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Step4：提交预测结果\n",
    "\n",
    "加载训练保存的模型加载后进行预测。\n",
    "\n",
    "**NOTE:** 注意设置用于预测的模型参数路径。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====start training of 0 epochs=====\n",
      "epoch: 0 / 3, steps: 0 / 5352, loss: 0.724830, speed: 103.25 step/s\n",
      "epoch: 0 / 3, steps: 50 / 5352, loss: 0.715500, speed: 4.19 step/s\n",
      "epoch: 0 / 3, steps: 100 / 5352, loss: 0.685553, speed: 4.21 step/s\n",
      "epoch: 0 / 3, steps: 150 / 5352, loss: 0.614880, speed: 4.22 step/s\n",
      "epoch: 0 / 3, steps: 200 / 5352, loss: 0.420222, speed: 4.20 step/s\n",
      "epoch: 0 / 3, steps: 250 / 5352, loss: 0.316304, speed: 4.21 step/s\n",
      "epoch: 0 / 3, steps: 300 / 5352, loss: 0.257368, speed: 4.20 step/s\n",
      "epoch: 0 / 3, steps: 350 / 5352, loss: 0.226483, speed: 4.16 step/s\n",
      "epoch: 0 / 3, steps: 400 / 5352, loss: 0.201163, speed: 4.18 step/s\n",
      "epoch: 0 / 3, steps: 450 / 5352, loss: 0.180056, speed: 4.21 step/s\n",
      "epoch: 0 / 3, steps: 500 / 5352, loss: 0.158638, speed: 4.20 step/s\n",
      "epoch: 0 / 3, steps: 550 / 5352, loss: 0.140370, speed: 4.16 step/s\n",
      "epoch: 0 / 3, steps: 600 / 5352, loss: 0.124322, speed: 3.95 step/s\n",
      "epoch: 0 / 3, steps: 650 / 5352, loss: 0.109564, speed: 3.97 step/s\n",
      "epoch: 0 / 3, steps: 700 / 5352, loss: 0.096888, speed: 3.95 step/s\n",
      "epoch: 0 / 3, steps: 750 / 5352, loss: 0.084769, speed: 3.95 step/s\n",
      "epoch: 0 / 3, steps: 800 / 5352, loss: 0.075541, speed: 3.95 step/s\n",
      "epoch: 0 / 3, steps: 850 / 5352, loss: 0.068158, speed: 3.93 step/s\n",
      "epoch: 0 / 3, steps: 900 / 5352, loss: 0.059427, speed: 3.95 step/s\n",
      "epoch: 0 / 3, steps: 950 / 5352, loss: 0.054799, speed: 3.95 step/s\n",
      "epoch: 0 / 3, steps: 1000 / 5352, loss: 0.049340, speed: 3.94 step/s\n",
      "epoch: 0 / 3, steps: 1050 / 5352, loss: 0.044464, speed: 3.93 step/s\n",
      "epoch: 0 / 3, steps: 1100 / 5352, loss: 0.041222, speed: 4.02 step/s\n",
      "epoch: 0 / 3, steps: 1150 / 5352, loss: 0.036507, speed: 4.18 step/s\n",
      "epoch: 0 / 3, steps: 1200 / 5352, loss: 0.034058, speed: 4.19 step/s\n",
      "epoch: 0 / 3, steps: 1250 / 5352, loss: 0.031611, speed: 4.19 step/s\n",
      "epoch: 0 / 3, steps: 1300 / 5352, loss: 0.028655, speed: 4.16 step/s\n",
      "epoch: 0 / 3, steps: 1350 / 5352, loss: 0.026497, speed: 4.16 step/s\n",
      "epoch: 0 / 3, steps: 1400 / 5352, loss: 0.024678, speed: 4.19 step/s\n",
      "epoch: 0 / 3, steps: 1450 / 5352, loss: 0.022441, speed: 4.19 step/s\n",
      "epoch: 0 / 3, steps: 1500 / 5352, loss: 0.020116, speed: 4.19 step/s\n",
      "epoch: 0 / 3, steps: 1550 / 5352, loss: 0.019124, speed: 4.15 step/s\n",
      "epoch: 0 / 3, steps: 1600 / 5352, loss: 0.018610, speed: 4.07 step/s\n",
      "epoch: 0 / 3, steps: 1650 / 5352, loss: 0.015967, speed: 4.03 step/s\n",
      "epoch: 0 / 3, steps: 1700 / 5352, loss: 0.015747, speed: 4.04 step/s\n",
      "epoch: 0 / 3, steps: 1750 / 5352, loss: 0.015120, speed: 4.05 step/s\n",
      "epoch: 0 / 3, steps: 1800 / 5352, loss: 0.014708, speed: 4.09 step/s\n",
      "epoch: 0 / 3, steps: 1850 / 5352, loss: 0.012597, speed: 4.11 step/s\n",
      "epoch: 0 / 3, steps: 1900 / 5352, loss: 0.013336, speed: 4.11 step/s\n",
      "epoch: 0 / 3, steps: 1950 / 5352, loss: 0.013776, speed: 4.11 step/s\n",
      "epoch: 0 / 3, steps: 2000 / 5352, loss: 0.012378, speed: 4.15 step/s\n",
      "epoch: 0 / 3, steps: 2050 / 5352, loss: 0.011059, speed: 4.13 step/s\n",
      "epoch: 0 / 3, steps: 2100 / 5352, loss: 0.010231, speed: 4.18 step/s\n",
      "epoch: 0 / 3, steps: 2150 / 5352, loss: 0.011364, speed: 4.26 step/s\n",
      "epoch: 0 / 3, steps: 2200 / 5352, loss: 0.010725, speed: 4.19 step/s\n",
      "epoch: 0 / 3, steps: 2250 / 5352, loss: 0.010665, speed: 4.08 step/s\n",
      "epoch: 0 / 3, steps: 2300 / 5352, loss: 0.010948, speed: 4.10 step/s\n",
      "epoch: 0 / 3, steps: 2350 / 5352, loss: 0.010465, speed: 4.11 step/s\n",
      "epoch: 0 / 3, steps: 2400 / 5352, loss: 0.009202, speed: 4.11 step/s\n",
      "epoch: 0 / 3, steps: 2450 / 5352, loss: 0.009478, speed: 4.12 step/s\n",
      "epoch: 0 / 3, steps: 2500 / 5352, loss: 0.008580, speed: 4.11 step/s\n",
      "epoch: 0 / 3, steps: 2550 / 5352, loss: 0.009017, speed: 4.10 step/s\n",
      "epoch: 0 / 3, steps: 2600 / 5352, loss: 0.008319, speed: 4.12 step/s\n",
      "epoch: 0 / 3, steps: 2650 / 5352, loss: 0.007142, speed: 4.09 step/s\n",
      "epoch: 0 / 3, steps: 2700 / 5352, loss: 0.008317, speed: 4.11 step/s\n",
      "epoch: 0 / 3, steps: 2750 / 5352, loss: 0.006975, speed: 4.12 step/s\n",
      "epoch: 0 / 3, steps: 2800 / 5352, loss: 0.007682, speed: 4.10 step/s\n",
      "epoch: 0 / 3, steps: 2850 / 5352, loss: 0.006212, speed: 4.11 step/s\n",
      "epoch: 0 / 3, steps: 2900 / 5352, loss: 0.007983, speed: 4.10 step/s\n",
      "epoch: 0 / 3, steps: 2950 / 5352, loss: 0.008346, speed: 3.94 step/s\n",
      "epoch: 0 / 3, steps: 3000 / 5352, loss: 0.008373, speed: 3.94 step/s\n",
      "epoch: 0 / 3, steps: 3050 / 5352, loss: 0.006525, speed: 3.95 step/s\n",
      "epoch: 0 / 3, steps: 3100 / 5352, loss: 0.005985, speed: 4.02 step/s\n",
      "epoch: 0 / 3, steps: 3150 / 5352, loss: 0.006590, speed: 4.12 step/s\n",
      "epoch: 0 / 3, steps: 3200 / 5352, loss: 0.005875, speed: 4.13 step/s\n",
      "epoch: 0 / 3, steps: 3250 / 5352, loss: 0.005825, speed: 4.11 step/s\n",
      "epoch: 0 / 3, steps: 3300 / 5352, loss: 0.008125, speed: 4.13 step/s\n",
      "epoch: 0 / 3, steps: 3350 / 5352, loss: 0.006681, speed: 4.12 step/s\n",
      "epoch: 0 / 3, steps: 3400 / 5352, loss: 0.005923, speed: 4.11 step/s\n",
      "epoch: 0 / 3, steps: 3450 / 5352, loss: 0.006575, speed: 4.11 step/s\n",
      "epoch: 0 / 3, steps: 3500 / 5352, loss: 0.005234, speed: 4.12 step/s\n",
      "epoch: 0 / 3, steps: 3550 / 5352, loss: 0.007056, speed: 4.12 step/s\n",
      "epoch: 0 / 3, steps: 3600 / 5352, loss: 0.005621, speed: 4.13 step/s\n",
      "epoch: 0 / 3, steps: 3650 / 5352, loss: 0.005292, speed: 4.12 step/s\n",
      "epoch: 0 / 3, steps: 3700 / 5352, loss: 0.005712, speed: 4.13 step/s\n",
      "epoch: 0 / 3, steps: 3750 / 5352, loss: 0.007488, speed: 4.13 step/s\n",
      "epoch: 0 / 3, steps: 3800 / 5352, loss: 0.004683, speed: 4.12 step/s\n",
      "epoch: 0 / 3, steps: 3850 / 5352, loss: 0.004681, speed: 4.15 step/s\n",
      "epoch: 0 / 3, steps: 3900 / 5352, loss: 0.004495, speed: 4.12 step/s\n",
      "epoch: 0 / 3, steps: 3950 / 5352, loss: 0.005237, speed: 4.11 step/s\n",
      "epoch: 0 / 3, steps: 4000 / 5352, loss: 0.005264, speed: 4.11 step/s\n",
      "epoch: 0 / 3, steps: 4050 / 5352, loss: 0.004924, speed: 4.10 step/s\n",
      "epoch: 0 / 3, steps: 4100 / 5352, loss: 0.004334, speed: 4.10 step/s\n",
      "epoch: 0 / 3, steps: 4150 / 5352, loss: 0.004870, speed: 4.10 step/s\n",
      "epoch: 0 / 3, steps: 4200 / 5352, loss: 0.004497, speed: 4.10 step/s\n",
      "epoch: 0 / 3, steps: 4250 / 5352, loss: 0.004528, speed: 4.12 step/s\n",
      "epoch: 0 / 3, steps: 4300 / 5352, loss: 0.004133, speed: 4.12 step/s\n",
      "epoch: 0 / 3, steps: 4350 / 5352, loss: 0.004880, speed: 4.11 step/s\n",
      "epoch: 0 / 3, steps: 4400 / 5352, loss: 0.004455, speed: 4.09 step/s\n",
      "epoch: 0 / 3, steps: 4450 / 5352, loss: 0.006547, speed: 4.12 step/s\n",
      "epoch: 0 / 3, steps: 4500 / 5352, loss: 0.004453, speed: 4.11 step/s\n",
      "epoch: 0 / 3, steps: 4550 / 5352, loss: 0.003968, speed: 4.12 step/s\n",
      "epoch: 0 / 3, steps: 4600 / 5352, loss: 0.004472, speed: 4.14 step/s\n",
      "epoch: 0 / 3, steps: 4650 / 5352, loss: 0.004785, speed: 4.10 step/s\n",
      "epoch: 0 / 3, steps: 4700 / 5352, loss: 0.004204, speed: 4.21 step/s\n",
      "epoch: 0 / 3, steps: 4750 / 5352, loss: 0.004106, speed: 4.21 step/s\n",
      "epoch: 0 / 3, steps: 4800 / 5352, loss: 0.004339, speed: 4.05 step/s\n",
      "epoch: 0 / 3, steps: 4850 / 5352, loss: 0.003836, speed: 4.11 step/s\n",
      "epoch: 0 / 3, steps: 4900 / 5352, loss: 0.004456, speed: 4.11 step/s\n",
      "epoch: 0 / 3, steps: 4950 / 5352, loss: 0.004368, speed: 4.10 step/s\n",
      "epoch: 0 / 3, steps: 5000 / 5352, loss: 0.003998, speed: 4.10 step/s\n",
      "epoch: 0 / 3, steps: 5050 / 5352, loss: 0.004353, speed: 4.10 step/s\n",
      "epoch: 0 / 3, steps: 5100 / 5352, loss: 0.004098, speed: 4.11 step/s\n",
      "epoch: 0 / 3, steps: 5150 / 5352, loss: 0.003981, speed: 4.09 step/s\n",
      "epoch: 0 / 3, steps: 5200 / 5352, loss: 0.004257, speed: 4.09 step/s\n",
      "epoch: 0 / 3, steps: 5250 / 5352, loss: 0.003492, speed: 4.07 step/s\n",
      "epoch: 0 / 3, steps: 5300 / 5352, loss: 0.003608, speed: 4.10 step/s\n",
      "epoch: 0 / 3, steps: 5350 / 5352, loss: 0.004236, speed: 4.09 step/s\n",
      "epoch time footprint: 0 hour 21 min 44 sec\n",
      "\n",
      "=====start training of 1 epochs=====\n",
      "epoch: 1 / 3, steps: 48 / 5352, loss: 0.003421, speed: 4.09 step/s\n",
      "epoch: 1 / 3, steps: 98 / 5352, loss: 0.003428, speed: 4.10 step/s\n",
      "epoch: 1 / 3, steps: 148 / 5352, loss: 0.004009, speed: 4.07 step/s\n",
      "epoch: 1 / 3, steps: 198 / 5352, loss: 0.003197, speed: 4.07 step/s\n",
      "epoch: 1 / 3, steps: 248 / 5352, loss: 0.004180, speed: 4.09 step/s\n",
      "epoch: 1 / 3, steps: 298 / 5352, loss: 0.002506, speed: 4.12 step/s\n",
      "epoch: 1 / 3, steps: 348 / 5352, loss: 0.003123, speed: 4.14 step/s\n",
      "epoch: 1 / 3, steps: 398 / 5352, loss: 0.004185, speed: 4.13 step/s\n",
      "epoch: 1 / 3, steps: 448 / 5352, loss: 0.003467, speed: 4.13 step/s\n",
      "epoch: 1 / 3, steps: 498 / 5352, loss: 0.003294, speed: 4.13 step/s\n",
      "epoch: 1 / 3, steps: 548 / 5352, loss: 0.003067, speed: 4.14 step/s\n",
      "epoch: 1 / 3, steps: 598 / 5352, loss: 0.003776, speed: 4.11 step/s\n",
      "epoch: 1 / 3, steps: 648 / 5352, loss: 0.003448, speed: 4.10 step/s\n",
      "epoch: 1 / 3, steps: 698 / 5352, loss: 0.003756, speed: 4.13 step/s\n",
      "epoch: 1 / 3, steps: 748 / 5352, loss: 0.003212, speed: 4.12 step/s\n",
      "epoch: 1 / 3, steps: 798 / 5352, loss: 0.004023, speed: 4.07 step/s\n",
      "epoch: 1 / 3, steps: 848 / 5352, loss: 0.002658, speed: 3.87 step/s\n",
      "epoch: 1 / 3, steps: 898 / 5352, loss: 0.005227, speed: 3.90 step/s\n",
      "epoch: 1 / 3, steps: 948 / 5352, loss: 0.003470, speed: 3.91 step/s\n",
      "epoch: 1 / 3, steps: 998 / 5352, loss: 0.002653, speed: 3.93 step/s\n",
      "epoch: 1 / 3, steps: 1048 / 5352, loss: 0.003668, speed: 3.91 step/s\n",
      "epoch: 1 / 3, steps: 1098 / 5352, loss: 0.003010, speed: 3.89 step/s\n",
      "epoch: 1 / 3, steps: 1148 / 5352, loss: 0.003477, speed: 4.09 step/s\n",
      "epoch: 1 / 3, steps: 1198 / 5352, loss: 0.003626, speed: 4.14 step/s\n",
      "epoch: 1 / 3, steps: 1248 / 5352, loss: 0.003087, speed: 4.12 step/s\n",
      "epoch: 1 / 3, steps: 1298 / 5352, loss: 0.002992, speed: 4.09 step/s\n",
      "epoch: 1 / 3, steps: 1348 / 5352, loss: 0.003510, speed: 4.10 step/s\n",
      "epoch: 1 / 3, steps: 1398 / 5352, loss: 0.003391, speed: 4.13 step/s\n",
      "epoch: 1 / 3, steps: 1448 / 5352, loss: 0.004807, speed: 4.13 step/s\n",
      "epoch: 1 / 3, steps: 1498 / 5352, loss: 0.003304, speed: 4.14 step/s\n",
      "epoch: 1 / 3, steps: 1548 / 5352, loss: 0.003464, speed: 4.14 step/s\n",
      "epoch: 1 / 3, steps: 1598 / 5352, loss: 0.002719, speed: 4.11 step/s\n",
      "epoch: 1 / 3, steps: 1648 / 5352, loss: 0.004559, speed: 4.13 step/s\n",
      "epoch: 1 / 3, steps: 1698 / 5352, loss: 0.003159, speed: 4.14 step/s\n",
      "epoch: 1 / 3, steps: 1748 / 5352, loss: 0.002398, speed: 4.15 step/s\n",
      "epoch: 1 / 3, steps: 1798 / 5352, loss: 0.002424, speed: 4.15 step/s\n",
      "epoch: 1 / 3, steps: 1848 / 5352, loss: 0.004072, speed: 4.12 step/s\n",
      "epoch: 1 / 3, steps: 1898 / 5352, loss: 0.002425, speed: 4.14 step/s\n",
      "epoch: 1 / 3, steps: 1948 / 5352, loss: 0.002919, speed: 4.14 step/s\n",
      "epoch: 1 / 3, steps: 1998 / 5352, loss: 0.002806, speed: 4.14 step/s\n",
      "epoch: 1 / 3, steps: 2048 / 5352, loss: 0.002957, speed: 4.14 step/s\n",
      "epoch: 1 / 3, steps: 2098 / 5352, loss: 0.002647, speed: 4.19 step/s\n",
      "epoch: 1 / 3, steps: 2148 / 5352, loss: 0.002628, speed: 4.24 step/s\n",
      "epoch: 1 / 3, steps: 2198 / 5352, loss: 0.002213, speed: 4.22 step/s\n",
      "epoch: 1 / 3, steps: 2248 / 5352, loss: 0.002322, speed: 4.24 step/s\n",
      "epoch: 1 / 3, steps: 2298 / 5352, loss: 0.002943, speed: 4.25 step/s\n",
      "epoch: 1 / 3, steps: 2348 / 5352, loss: 0.002776, speed: 4.23 step/s\n",
      "epoch: 1 / 3, steps: 2398 / 5352, loss: 0.002433, speed: 4.24 step/s\n",
      "epoch: 1 / 3, steps: 2448 / 5352, loss: 0.002613, speed: 4.22 step/s\n",
      "epoch: 1 / 3, steps: 2498 / 5352, loss: 0.003024, speed: 4.25 step/s\n",
      "epoch: 1 / 3, steps: 2548 / 5352, loss: 0.003939, speed: 4.25 step/s\n",
      "epoch: 1 / 3, steps: 2598 / 5352, loss: 0.002274, speed: 4.24 step/s\n",
      "epoch: 1 / 3, steps: 2648 / 5352, loss: 0.003065, speed: 4.24 step/s\n",
      "epoch: 1 / 3, steps: 2698 / 5352, loss: 0.003225, speed: 4.25 step/s\n",
      "epoch: 1 / 3, steps: 2748 / 5352, loss: 0.002137, speed: 4.23 step/s\n",
      "epoch: 1 / 3, steps: 2798 / 5352, loss: 0.002428, speed: 4.25 step/s\n",
      "epoch: 1 / 3, steps: 2848 / 5352, loss: 0.002263, speed: 4.22 step/s\n",
      "epoch: 1 / 3, steps: 2898 / 5352, loss: 0.003104, speed: 4.22 step/s\n",
      "epoch: 1 / 3, steps: 2948 / 5352, loss: 0.002364, speed: 4.21 step/s\n",
      "epoch: 1 / 3, steps: 2998 / 5352, loss: 0.003603, speed: 4.23 step/s\n",
      "epoch: 1 / 3, steps: 3048 / 5352, loss: 0.004184, speed: 4.17 step/s\n",
      "epoch: 1 / 3, steps: 3098 / 5352, loss: 0.003594, speed: 3.89 step/s\n",
      "epoch: 1 / 3, steps: 3148 / 5352, loss: 0.001910, speed: 4.01 step/s\n",
      "epoch: 1 / 3, steps: 3198 / 5352, loss: 0.002621, speed: 4.20 step/s\n",
      "epoch: 1 / 3, steps: 3248 / 5352, loss: 0.003141, speed: 4.21 step/s\n",
      "epoch: 1 / 3, steps: 3298 / 5352, loss: 0.002577, speed: 4.14 step/s\n",
      "epoch: 1 / 3, steps: 3348 / 5352, loss: 0.002396, speed: 4.15 step/s\n",
      "epoch: 1 / 3, steps: 3398 / 5352, loss: 0.003606, speed: 4.14 step/s\n",
      "epoch: 1 / 3, steps: 3448 / 5352, loss: 0.003343, speed: 4.13 step/s\n",
      "epoch: 1 / 3, steps: 3498 / 5352, loss: 0.002650, speed: 4.15 step/s\n",
      "epoch: 1 / 3, steps: 3548 / 5352, loss: 0.002375, speed: 4.14 step/s\n",
      "epoch: 1 / 3, steps: 3598 / 5352, loss: 0.002521, speed: 4.05 step/s\n",
      "epoch: 1 / 3, steps: 3648 / 5352, loss: 0.002931, speed: 4.16 step/s\n",
      "epoch: 1 / 3, steps: 3698 / 5352, loss: 0.002876, speed: 4.20 step/s\n",
      "epoch: 1 / 3, steps: 3748 / 5352, loss: 0.002635, speed: 4.21 step/s\n",
      "epoch: 1 / 3, steps: 3798 / 5352, loss: 0.002022, speed: 4.14 step/s\n",
      "epoch: 1 / 3, steps: 3848 / 5352, loss: 0.002679, speed: 4.11 step/s\n",
      "epoch: 1 / 3, steps: 3898 / 5352, loss: 0.002511, speed: 4.11 step/s\n",
      "epoch: 1 / 3, steps: 3948 / 5352, loss: 0.001852, speed: 4.11 step/s\n",
      "epoch: 1 / 3, steps: 3998 / 5352, loss: 0.003061, speed: 4.28 step/s\n",
      "epoch: 1 / 3, steps: 4048 / 5352, loss: 0.002164, speed: 4.27 step/s\n",
      "epoch: 1 / 3, steps: 4098 / 5352, loss: 0.002023, speed: 4.25 step/s\n",
      "epoch: 1 / 3, steps: 4148 / 5352, loss: 0.002929, speed: 4.26 step/s\n",
      "epoch: 1 / 3, steps: 4198 / 5352, loss: 0.002644, speed: 4.27 step/s\n",
      "epoch: 1 / 3, steps: 4248 / 5352, loss: 0.002169, speed: 4.10 step/s\n",
      "epoch: 1 / 3, steps: 4298 / 5352, loss: 0.002690, speed: 4.09 step/s\n",
      "epoch: 1 / 3, steps: 4348 / 5352, loss: 0.001871, speed: 4.10 step/s\n",
      "epoch: 1 / 3, steps: 4398 / 5352, loss: 0.002840, speed: 4.24 step/s\n",
      "epoch: 1 / 3, steps: 4448 / 5352, loss: 0.002860, speed: 4.15 step/s\n",
      "epoch: 1 / 3, steps: 4498 / 5352, loss: 0.002150, speed: 4.16 step/s\n",
      "epoch: 1 / 3, steps: 4548 / 5352, loss: 0.002364, speed: 4.15 step/s\n",
      "epoch: 1 / 3, steps: 4598 / 5352, loss: 0.002166, speed: 4.14 step/s\n",
      "epoch: 1 / 3, steps: 4648 / 5352, loss: 0.002848, speed: 4.15 step/s\n",
      "\n",
      "=====start evaluating ckpt of 10000 steps=====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 646/646 [01:01<00:00, 10.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss: 0.002520\n",
      "precision: 58.82\t recall: 65.87\t f1: 62.14\t\n",
      "saving checkpoing model_10000.pdparams to checkpoints \n",
      "epoch: 1 / 3, steps: 4698 / 5352, loss: 0.002406, speed: 0.60 step/s\n",
      "epoch: 1 / 3, steps: 4748 / 5352, loss: 0.002833, speed: 4.29 step/s\n",
      "epoch: 1 / 3, steps: 4798 / 5352, loss: 0.003121, speed: 4.27 step/s\n",
      "epoch: 1 / 3, steps: 4848 / 5352, loss: 0.002453, speed: 4.26 step/s\n",
      "epoch: 1 / 3, steps: 4898 / 5352, loss: 0.002991, speed: 4.24 step/s\n",
      "epoch: 1 / 3, steps: 4948 / 5352, loss: 0.002387, speed: 4.27 step/s\n",
      "epoch: 1 / 3, steps: 4998 / 5352, loss: 0.002143, speed: 4.26 step/s\n",
      "epoch: 1 / 3, steps: 5048 / 5352, loss: 0.002689, speed: 4.27 step/s\n",
      "epoch: 1 / 3, steps: 5098 / 5352, loss: 0.002758, speed: 4.26 step/s\n",
      "epoch: 1 / 3, steps: 5148 / 5352, loss: 0.003006, speed: 4.03 step/s\n",
      "epoch: 1 / 3, steps: 5198 / 5352, loss: 0.001974, speed: 3.91 step/s\n",
      "epoch: 1 / 3, steps: 5248 / 5352, loss: 0.002447, speed: 3.93 step/s\n",
      "epoch: 1 / 3, steps: 5298 / 5352, loss: 0.002881, speed: 4.06 step/s\n",
      "epoch: 1 / 3, steps: 5348 / 5352, loss: 0.002600, speed: 4.13 step/s\n",
      "epoch time footprint: 0 hour 22 min 43 sec\n",
      "\n",
      "=====start training of 2 epochs=====\n",
      "epoch: 2 / 3, steps: 46 / 5352, loss: 0.002702, speed: 4.14 step/s\n",
      "epoch: 2 / 3, steps: 96 / 5352, loss: 0.002040, speed: 4.14 step/s\n",
      "epoch: 2 / 3, steps: 146 / 5352, loss: 0.001864, speed: 4.15 step/s\n",
      "epoch: 2 / 3, steps: 196 / 5352, loss: 0.002494, speed: 4.13 step/s\n",
      "epoch: 2 / 3, steps: 246 / 5352, loss: 0.002002, speed: 4.14 step/s\n",
      "epoch: 2 / 3, steps: 296 / 5352, loss: 0.002349, speed: 4.23 step/s\n",
      "epoch: 2 / 3, steps: 346 / 5352, loss: 0.002685, speed: 4.28 step/s\n",
      "epoch: 2 / 3, steps: 396 / 5352, loss: 0.003550, speed: 4.28 step/s\n",
      "epoch: 2 / 3, steps: 446 / 5352, loss: 0.002544, speed: 4.25 step/s\n",
      "epoch: 2 / 3, steps: 496 / 5352, loss: 0.002574, speed: 3.97 step/s\n",
      "epoch: 2 / 3, steps: 546 / 5352, loss: 0.002176, speed: 4.15 step/s\n",
      "epoch: 2 / 3, steps: 596 / 5352, loss: 0.002534, speed: 4.16 step/s\n",
      "epoch: 2 / 3, steps: 646 / 5352, loss: 0.001936, speed: 4.24 step/s\n",
      "epoch: 2 / 3, steps: 696 / 5352, loss: 0.003217, speed: 4.24 step/s\n",
      "epoch: 2 / 3, steps: 746 / 5352, loss: 0.002912, speed: 4.25 step/s\n",
      "epoch: 2 / 3, steps: 796 / 5352, loss: 0.001615, speed: 4.23 step/s\n",
      "epoch: 2 / 3, steps: 846 / 5352, loss: 0.002357, speed: 4.19 step/s\n",
      "epoch: 2 / 3, steps: 896 / 5352, loss: 0.002578, speed: 4.27 step/s\n",
      "epoch: 2 / 3, steps: 946 / 5352, loss: 0.001952, speed: 3.93 step/s\n",
      "epoch: 2 / 3, steps: 996 / 5352, loss: 0.002172, speed: 3.90 step/s\n",
      "epoch: 2 / 3, steps: 1046 / 5352, loss: 0.001533, speed: 3.94 step/s\n",
      "epoch: 2 / 3, steps: 1096 / 5352, loss: 0.002209, speed: 4.24 step/s\n",
      "epoch: 2 / 3, steps: 1146 / 5352, loss: 0.001897, speed: 4.23 step/s\n",
      "epoch: 2 / 3, steps: 1196 / 5352, loss: 0.002411, speed: 4.20 step/s\n",
      "epoch: 2 / 3, steps: 1246 / 5352, loss: 0.002228, speed: 3.91 step/s\n",
      "epoch: 2 / 3, steps: 1296 / 5352, loss: 0.001813, speed: 3.91 step/s\n",
      "epoch: 2 / 3, steps: 1346 / 5352, loss: 0.002304, speed: 4.14 step/s\n",
      "epoch: 2 / 3, steps: 1396 / 5352, loss: 0.001405, speed: 4.24 step/s\n",
      "epoch: 2 / 3, steps: 1446 / 5352, loss: 0.001748, speed: 4.16 step/s\n",
      "epoch: 2 / 3, steps: 1496 / 5352, loss: 0.001519, speed: 4.15 step/s\n",
      "epoch: 2 / 3, steps: 1546 / 5352, loss: 0.002800, speed: 4.23 step/s\n",
      "epoch: 2 / 3, steps: 1596 / 5352, loss: 0.002054, speed: 4.23 step/s\n",
      "epoch: 2 / 3, steps: 1646 / 5352, loss: 0.001952, speed: 4.25 step/s\n",
      "epoch: 2 / 3, steps: 1696 / 5352, loss: 0.002142, speed: 4.24 step/s\n",
      "epoch: 2 / 3, steps: 1746 / 5352, loss: 0.002192, speed: 4.26 step/s\n",
      "epoch: 2 / 3, steps: 1796 / 5352, loss: 0.002254, speed: 4.23 step/s\n",
      "epoch: 2 / 3, steps: 1846 / 5352, loss: 0.001887, speed: 4.24 step/s\n",
      "epoch: 2 / 3, steps: 1896 / 5352, loss: 0.002381, speed: 4.23 step/s\n",
      "epoch: 2 / 3, steps: 1946 / 5352, loss: 0.002906, speed: 4.23 step/s\n",
      "epoch: 2 / 3, steps: 1996 / 5352, loss: 0.001667, speed: 4.23 step/s\n",
      "epoch: 2 / 3, steps: 2046 / 5352, loss: 0.002017, speed: 4.24 step/s\n",
      "epoch: 2 / 3, steps: 2096 / 5352, loss: 0.002161, speed: 4.22 step/s\n",
      "epoch: 2 / 3, steps: 2146 / 5352, loss: 0.003245, speed: 4.25 step/s\n",
      "epoch: 2 / 3, steps: 2196 / 5352, loss: 0.002308, speed: 4.24 step/s\n",
      "epoch: 2 / 3, steps: 2246 / 5352, loss: 0.002801, speed: 4.23 step/s\n",
      "epoch: 2 / 3, steps: 2296 / 5352, loss: 0.001933, speed: 4.25 step/s\n",
      "epoch: 2 / 3, steps: 2346 / 5352, loss: 0.002125, speed: 4.22 step/s\n",
      "epoch: 2 / 3, steps: 2396 / 5352, loss: 0.001765, speed: 4.23 step/s\n",
      "epoch: 2 / 3, steps: 2446 / 5352, loss: 0.001808, speed: 4.25 step/s\n",
      "epoch: 2 / 3, steps: 2496 / 5352, loss: 0.002541, speed: 4.24 step/s\n",
      "epoch: 2 / 3, steps: 2546 / 5352, loss: 0.001702, speed: 4.17 step/s\n",
      "epoch: 2 / 3, steps: 2596 / 5352, loss: 0.001898, speed: 4.14 step/s\n",
      "epoch: 2 / 3, steps: 2646 / 5352, loss: 0.002448, speed: 4.16 step/s\n",
      "epoch: 2 / 3, steps: 2696 / 5352, loss: 0.001840, speed: 4.20 step/s\n",
      "epoch: 2 / 3, steps: 2746 / 5352, loss: 0.002708, speed: 4.13 step/s\n",
      "epoch: 2 / 3, steps: 2796 / 5352, loss: 0.001269, speed: 4.16 step/s\n",
      "epoch: 2 / 3, steps: 2846 / 5352, loss: 0.002709, speed: 4.15 step/s\n",
      "epoch: 2 / 3, steps: 2896 / 5352, loss: 0.002835, speed: 4.14 step/s\n",
      "epoch: 2 / 3, steps: 2946 / 5352, loss: 0.002232, speed: 4.14 step/s\n",
      "epoch: 2 / 3, steps: 2996 / 5352, loss: 0.002119, speed: 4.13 step/s\n",
      "epoch: 2 / 3, steps: 3046 / 5352, loss: 0.002310, speed: 4.15 step/s\n",
      "epoch: 2 / 3, steps: 3096 / 5352, loss: 0.001713, speed: 4.14 step/s\n",
      "epoch: 2 / 3, steps: 3146 / 5352, loss: 0.003847, speed: 4.13 step/s\n",
      "epoch: 2 / 3, steps: 3196 / 5352, loss: 0.001494, speed: 4.12 step/s\n",
      "epoch: 2 / 3, steps: 3246 / 5352, loss: 0.001608, speed: 4.15 step/s\n",
      "epoch: 2 / 3, steps: 3296 / 5352, loss: 0.001989, speed: 4.15 step/s\n",
      "epoch: 2 / 3, steps: 3346 / 5352, loss: 0.002219, speed: 4.13 step/s\n",
      "epoch: 2 / 3, steps: 3396 / 5352, loss: 0.002046, speed: 4.14 step/s\n",
      "epoch: 2 / 3, steps: 3446 / 5352, loss: 0.002475, speed: 4.14 step/s\n",
      "epoch: 2 / 3, steps: 3496 / 5352, loss: 0.001270, speed: 4.15 step/s\n",
      "epoch: 2 / 3, steps: 3546 / 5352, loss: 0.002210, speed: 4.15 step/s\n",
      "epoch: 2 / 3, steps: 3596 / 5352, loss: 0.001612, speed: 4.18 step/s\n",
      "epoch: 2 / 3, steps: 3646 / 5352, loss: 0.001421, speed: 4.19 step/s\n",
      "epoch: 2 / 3, steps: 3696 / 5352, loss: 0.002163, speed: 4.12 step/s\n",
      "epoch: 2 / 3, steps: 3746 / 5352, loss: 0.002823, speed: 4.13 step/s\n",
      "epoch: 2 / 3, steps: 3796 / 5352, loss: 0.001521, speed: 4.26 step/s\n",
      "epoch: 2 / 3, steps: 3846 / 5352, loss: 0.003167, speed: 4.26 step/s\n",
      "epoch: 2 / 3, steps: 3896 / 5352, loss: 0.002344, speed: 4.24 step/s\n",
      "epoch: 2 / 3, steps: 3946 / 5352, loss: 0.002306, speed: 4.26 step/s\n",
      "epoch: 2 / 3, steps: 3996 / 5352, loss: 0.003790, speed: 4.27 step/s\n",
      "epoch: 2 / 3, steps: 4046 / 5352, loss: 0.002698, speed: 4.27 step/s\n",
      "epoch: 2 / 3, steps: 4096 / 5352, loss: 0.002776, speed: 4.13 step/s\n",
      "epoch: 2 / 3, steps: 4146 / 5352, loss: 0.001901, speed: 4.14 step/s\n",
      "epoch: 2 / 3, steps: 4196 / 5352, loss: 0.001475, speed: 4.12 step/s\n",
      "epoch: 2 / 3, steps: 4246 / 5352, loss: 0.001996, speed: 4.09 step/s\n",
      "epoch: 2 / 3, steps: 4296 / 5352, loss: 0.002420, speed: 4.12 step/s\n",
      "epoch: 2 / 3, steps: 4346 / 5352, loss: 0.001991, speed: 4.23 step/s\n",
      "epoch: 2 / 3, steps: 4396 / 5352, loss: 0.001576, speed: 4.26 step/s\n",
      "epoch: 2 / 3, steps: 4446 / 5352, loss: 0.002646, speed: 4.21 step/s\n",
      "epoch: 2 / 3, steps: 4496 / 5352, loss: 0.001816, speed: 4.25 step/s\n",
      "epoch: 2 / 3, steps: 4546 / 5352, loss: 0.002766, speed: 4.24 step/s\n",
      "epoch: 2 / 3, steps: 4596 / 5352, loss: 0.001757, speed: 4.16 step/s\n",
      "epoch: 2 / 3, steps: 4646 / 5352, loss: 0.001799, speed: 4.16 step/s\n",
      "epoch: 2 / 3, steps: 4696 / 5352, loss: 0.001304, speed: 4.17 step/s\n",
      "epoch: 2 / 3, steps: 4746 / 5352, loss: 0.001480, speed: 4.27 step/s\n",
      "epoch: 2 / 3, steps: 4796 / 5352, loss: 0.001725, speed: 4.28 step/s\n",
      "epoch: 2 / 3, steps: 4846 / 5352, loss: 0.003023, speed: 4.28 step/s\n",
      "epoch: 2 / 3, steps: 4896 / 5352, loss: 0.001610, speed: 4.25 step/s\n",
      "epoch: 2 / 3, steps: 4946 / 5352, loss: 0.002016, speed: 4.22 step/s\n",
      "epoch: 2 / 3, steps: 4996 / 5352, loss: 0.002194, speed: 4.24 step/s\n",
      "epoch: 2 / 3, steps: 5046 / 5352, loss: 0.003227, speed: 4.24 step/s\n",
      "epoch: 2 / 3, steps: 5096 / 5352, loss: 0.002325, speed: 4.25 step/s\n",
      "epoch: 2 / 3, steps: 5146 / 5352, loss: 0.002188, speed: 4.26 step/s\n",
      "epoch: 2 / 3, steps: 5196 / 5352, loss: 0.001462, speed: 4.23 step/s\n",
      "epoch: 2 / 3, steps: 5246 / 5352, loss: 0.002042, speed: 4.23 step/s\n",
      "epoch: 2 / 3, steps: 5296 / 5352, loss: 0.002084, speed: 4.24 step/s\n",
      "epoch: 2 / 3, steps: 5346 / 5352, loss: 0.002060, speed: 4.24 step/s\n",
      "epoch time footprint: 0 hour 21 min 19 sec\n",
      "\n",
      "=====start evaluating last ckpt of 16056 steps=====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 646/646 [01:02<00:00, 10.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss: 0.002206\n",
      "precision: 60.93\t recall: 70.32\t f1: 65.29\t\n",
      "\n",
      "=====training complete=====\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import paddle.nn.functional as F\n",
    "\n",
    "# Starts training.\n",
    "global_step = 0\n",
    "logging_steps = 50\n",
    "save_steps = 10000\n",
    "num_train_epochs = 3\n",
    "output_dir = 'checkpoints'\n",
    "tic_train = time.time()\n",
    "model.train()\n",
    "for epoch in range(num_train_epochs):\n",
    "    print(\"\\n=====start training of %d epochs=====\" % epoch)\n",
    "    tic_epoch = time.time()\n",
    "    for step, batch in enumerate(train_data_loader):\n",
    "        input_ids, seq_lens, tok_to_orig_start_index, tok_to_orig_end_index, labels = batch\n",
    "        logits = model(input_ids=input_ids)\n",
    "        mask = (input_ids != 0).logical_and((input_ids != 1)).logical_and(\n",
    "            (input_ids != 2))\n",
    "        loss = criterion(logits, labels, mask)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.clear_gradients()\n",
    "        loss_item = loss.numpy().item()\n",
    "\n",
    "        if global_step % logging_steps == 0:\n",
    "            print(\n",
    "                \"epoch: %d / %d, steps: %d / %d, loss: %f, speed: %.2f step/s\"\n",
    "                % (epoch, num_train_epochs, step, steps_by_epoch,\n",
    "                    loss_item, logging_steps / (time.time() - tic_train)))\n",
    "            tic_train = time.time()\n",
    "\n",
    "        if global_step % save_steps == 0 and global_step != 0:\n",
    "            print(\"\\n=====start evaluating ckpt of %d steps=====\" %\n",
    "                    global_step)\n",
    "            precision, recall, f1 = evaluate(\n",
    "                model, criterion, test_data_loader, eval_file_path, \"eval\")\n",
    "            print(\"precision: %.2f\\t recall: %.2f\\t f1: %.2f\\t\" %\n",
    "                    (100 * precision, 100 * recall, 100 * f1))\n",
    "            print(\"saving checkpoing model_%d.pdparams to %s \" %\n",
    "                    (global_step, output_dir))\n",
    "            paddle.save(model.state_dict(),\n",
    "                        os.path.join(output_dir, \n",
    "                                        \"model_%d.pdparams\" % global_step))\n",
    "            model.train()\n",
    "\n",
    "        global_step += 1\n",
    "    tic_epoch = time.time() - tic_epoch\n",
    "    print(\"epoch time footprint: %d hour %d min %d sec\" %\n",
    "            (tic_epoch // 3600, (tic_epoch % 3600) // 60, tic_epoch % 60))\n",
    "\n",
    "# Does final evaluation.\n",
    "print(\"\\n=====start evaluating last ckpt of %d steps=====\" %\n",
    "        global_step)\n",
    "precision, recall, f1 = evaluate(model, criterion, test_data_loader,\n",
    "                                    eval_file_path, \"eval\")\n",
    "print(\"precision: %.2f\\t recall: %.2f\\t f1: %.2f\\t\" %\n",
    "        (100 * precision, 100 * recall, 100 * f1))\n",
    "paddle.save(model.state_dict(),\n",
    "            os.path.join(output_dir,\n",
    "                            \"model_%d.pdparams\" % global_step))\n",
    "print(\"\\n=====training complete=====\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# !bash predict.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "预测结果会被保存在data/predictions.json，data/predictions.json.zip，其格式与原数据集文件一致。\n",
    "\n",
    "之后可以使用官方评估脚本评估训练模型在dev_data.json上的效果。如：\n",
    "\n",
    "```shell\n",
    "python re_official_evaluation.py --golden_file=dev_data.json  --predict_file=predicitons.json.zip [--alias_file alias_dict]\n",
    "```\n",
    "输出指标为Precision, Recall 和 F1，Alias file包含了合法的实体别名，最终评测的时候会使用，这里不予提供。\n",
    "\n",
    "之后在test_data.json上预测，然后预测结果（.zip文件）至[千言评测页面](https://aistudio.baidu.com/aistudio/competition/detail/46)。\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "## Tricks\n",
    "\n",
    "### 尝试更多的预训练模型\n",
    "\n",
    "基线采用的预训练模型为ERNIE，PaddleNLP提供了丰富的预训练模型，如BERT，RoBERTa，Electra，XLNet等\n",
    "参考[预训练模型文档](https://paddlenlp.readthedocs.io/zh/latest/model_zoo/transformers.html)\n",
    "\n",
    "如可以选择RoBERTa large中文模型优化模型效果，只需更换模型和tokenizer即可无缝衔接。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from paddlenlp.transformers import RobertaForTokenClassification, RobertaTokenizer\n",
    "\n",
    "# model = RobertaForTokenClassification.from_pretrained(\n",
    "#     \"roberta-wwm-ext-large\",\n",
    "#     num_classes=(len(label_map) - 2) * 2 + 2)\n",
    "# tokenizer = RobertaTokenizer.from_pretrained(\"roberta-wwm-ext-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-06-18 09:11:27,406] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/roberta-wwm-ext-large/roberta_chn_large.pdparams\n",
      "[2021-06-18 09:11:32,429] [    INFO] - Found /home/aistudio/.paddlenlp/models/roberta-wwm-ext-large/vocab.txt\n"
     ]
    }
   ],
   "source": [
    "import os\r\n",
    "import json\r\n",
    "from paddlenlp.transformers import RobertaForTokenClassification, RobertaTokenizer\r\n",
    "import sys\r\n",
    "\r\n",
    "label_map_path = os.path.join('data', \"predicate2id.json\")\r\n",
    "\r\n",
    "if not (os.path.exists(label_map_path) and os.path.isfile(label_map_path)):\r\n",
    "    sys.exit(\"{} dose not exists or is not a file.\".format(label_map_path))\r\n",
    "with open(label_map_path, 'r', encoding='utf8') as fp:\r\n",
    "    label_map = json.load(fp)\r\n",
    "    \r\n",
    "num_classes = (len(label_map.keys()) - 2) * 2 + 2\r\n",
    "\r\n",
    "# 补齐代码，理解TokenClassification接口含义，理解关系抽取标注体系和类别数由来\r\n",
    "# model = ErnieForTokenClassification.from_pretrained(\"ernie-1.0\", num_classes=num_classes)\r\n",
    "# model = ErnieForTokenClassification.from_pretrained(\"ernie-1.0\", num_classes=(len(label_map) - 2) * 2 + 2)\r\n",
    "# tokenizer = ErnieTokenizer.from_pretrained(\"ernie-1.0\")\r\n",
    "\r\n",
    "model = RobertaForTokenClassification.from_pretrained(\r\n",
    "    \"roberta-wwm-ext-large\",\r\n",
    "    num_classes=(len(label_map) - 2) * 2 + 2)\r\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-wwm-ext-large\")\r\n",
    "\r\n",
    "inputs = tokenizer(text=\"请输入测试样例\", max_seq_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from typing import Optional, List, Union, Dict\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import paddle\r\n",
    "from tqdm import tqdm\r\n",
    "from paddlenlp.utils.log import logger\r\n",
    "\r\n",
    "from data_loader import parse_label, DataCollator, convert_example_to_feature\r\n",
    "from extract_chinese_and_punct import ChineseAndPunctuationExtractor\r\n",
    "\r\n",
    "\r\n",
    "class DuIEDataset(paddle.io.Dataset):\r\n",
    "    \"\"\"\r\n",
    "    Dataset of DuIE.\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    def __init__(\r\n",
    "            self,\r\n",
    "            input_ids: List[Union[List[int], np.ndarray]],\r\n",
    "            seq_lens: List[Union[List[int], np.ndarray]],\r\n",
    "            tok_to_orig_start_index: List[Union[List[int], np.ndarray]],\r\n",
    "            tok_to_orig_end_index: List[Union[List[int], np.ndarray]],\r\n",
    "            labels: List[Union[List[int], np.ndarray, List[str], List[Dict]]]):\r\n",
    "        super(DuIEDataset, self).__init__()\r\n",
    "\r\n",
    "        self.input_ids = input_ids\r\n",
    "        self.seq_lens = seq_lens\r\n",
    "        self.tok_to_orig_start_index = tok_to_orig_start_index\r\n",
    "        self.tok_to_orig_end_index = tok_to_orig_end_index\r\n",
    "        self.labels = labels\r\n",
    "\r\n",
    "    def __len__(self):\r\n",
    "        if isinstance(self.input_ids, np.ndarray):\r\n",
    "            return self.input_ids.shape[0]\r\n",
    "        else:\r\n",
    "            return len(self.input_ids)\r\n",
    "\r\n",
    "    def __getitem__(self, item):\r\n",
    "        return {\r\n",
    "            \"input_ids\": np.array(self.input_ids[item]),\r\n",
    "            \"seq_lens\": np.array(self.seq_lens[item]),\r\n",
    "            \"tok_to_orig_start_index\":\r\n",
    "            np.array(self.tok_to_orig_start_index[item]),\r\n",
    "            \"tok_to_orig_end_index\": np.array(self.tok_to_orig_end_index[item]),\r\n",
    "            # If model inputs is generated in `collate_fn`, delete the data type casting.\r\n",
    "            \"labels\": np.array(\r\n",
    "                self.labels[item], dtype=np.float32),\r\n",
    "        }\r\n",
    "\r\n",
    "    @classmethod\r\n",
    "    def from_file(cls,\r\n",
    "                  file_path: Union[str, os.PathLike],\r\n",
    "                  tokenizer: ErnieTokenizer,\r\n",
    "                  max_length: Optional[int]=512,\r\n",
    "                  pad_to_max_length: Optional[bool]=None):\r\n",
    "        assert os.path.exists(file_path) and os.path.isfile(\r\n",
    "            file_path), f\"{file_path} dose not exists or is not a file.\"\r\n",
    "        label_map_path = os.path.join(\r\n",
    "            os.path.dirname(file_path), \"predicate2id.json\")\r\n",
    "        assert os.path.exists(label_map_path) and os.path.isfile(\r\n",
    "            label_map_path\r\n",
    "        ), f\"{label_map_path} dose not exists or is not a file.\"\r\n",
    "        with open(label_map_path, 'r', encoding='utf8') as fp:\r\n",
    "            label_map = json.load(fp)\r\n",
    "        chineseandpunctuationextractor = ChineseAndPunctuationExtractor()\r\n",
    "\r\n",
    "        input_ids, seq_lens, tok_to_orig_start_index, tok_to_orig_end_index, labels = (\r\n",
    "            [] for _ in range(5))\r\n",
    "        dataset_scale = sum(1 for line in open(file_path, 'r'))\r\n",
    "        logger.info(\"Preprocessing data, loaded from %s\" % file_path)\r\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as fp:\r\n",
    "            lines = fp.readlines()\r\n",
    "            for line in tqdm(lines):\r\n",
    "                example = json.loads(line)\r\n",
    "                input_feature = convert_example_to_feature(\r\n",
    "                    example, tokenizer, chineseandpunctuationextractor,\r\n",
    "                    label_map, max_length, pad_to_max_length)\r\n",
    "                input_ids.append(input_feature.input_ids)\r\n",
    "                seq_lens.append(input_feature.seq_len)\r\n",
    "                tok_to_orig_start_index.append(\r\n",
    "                    input_feature.tok_to_orig_start_index)\r\n",
    "                tok_to_orig_end_index.append(\r\n",
    "                    input_feature.tok_to_orig_end_index)\r\n",
    "                labels.append(input_feature.labels)\r\n",
    "\r\n",
    "        return cls(input_ids, seq_lens, tok_to_orig_start_index,\r\n",
    "                   tok_to_orig_end_index, labels)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-06-18 09:11:38,665] [    INFO] - Preprocessing data, loaded from data/train.json\n",
      "100%|██████████| 171293/171293 [05:13<00:00, 546.16it/s]\n",
      "[2021-06-18 09:16:52,721] [    INFO] - Preprocessing data, loaded from data/dev.json\n",
      "100%|██████████| 20674/20674 [00:37<00:00, 545.17it/s]\n"
     ]
    }
   ],
   "source": [
    "data_path = 'data'\r\n",
    "batch_size = 32\r\n",
    "max_seq_length = 128\r\n",
    "\r\n",
    "train_file_path = os.path.join(data_path, 'train.json')\r\n",
    "train_dataset = DuIEDataset.from_file(\r\n",
    "    train_file_path, tokenizer, max_seq_length, True)\r\n",
    "train_batch_sampler = paddle.io.BatchSampler(\r\n",
    "    train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\r\n",
    "collator = DataCollator()\r\n",
    "train_data_loader = paddle.io.DataLoader(\r\n",
    "    dataset=train_dataset,\r\n",
    "    batch_sampler=train_batch_sampler,\r\n",
    "    collate_fn=collator)\r\n",
    "\r\n",
    "eval_file_path = os.path.join(data_path, 'dev.json')\r\n",
    "test_dataset = DuIEDataset.from_file(\r\n",
    "    eval_file_path, tokenizer, max_seq_length, True)\r\n",
    "test_batch_sampler = paddle.io.BatchSampler(\r\n",
    "    test_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\r\n",
    "test_data_loader = paddle.io.DataLoader(\r\n",
    "    dataset=test_dataset,\r\n",
    "    batch_sampler=test_batch_sampler,\r\n",
    "    collate_fn=collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import paddle.nn as nn\r\n",
    "\r\n",
    "class BCELossForDuIE(nn.Layer):\r\n",
    "    def __init__(self, ):\r\n",
    "        super(BCELossForDuIE, self).__init__()\r\n",
    "        self.criterion = nn.BCEWithLogitsLoss(reduction='none')\r\n",
    "\r\n",
    "    def forward(self, logits, labels, mask):\r\n",
    "        loss = self.criterion(logits, labels)\r\n",
    "        mask = paddle.cast(mask, 'float32')\r\n",
    "        loss = loss * mask.unsqueeze(-1)\r\n",
    "        loss = paddle.sum(loss.mean(axis=2), axis=1) / paddle.sum(mask, axis=1)\r\n",
    "        loss = loss.mean()\r\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils import write_prediction_results, get_precision_recall_f1, decoding\r\n",
    "\r\n",
    "@paddle.no_grad()\r\n",
    "def evaluate(model, criterion, data_loader, file_path, mode):\r\n",
    "    \"\"\"\r\n",
    "    mode eval:\r\n",
    "    eval on development set and compute P/R/F1, called between training.\r\n",
    "    mode predict:\r\n",
    "    eval on development / test set, then write predictions to \\\r\n",
    "        predict_test.json and predict_test.json.zip \\\r\n",
    "        under /home/aistudio/relation_extraction/data dir for later submission or evaluation.\r\n",
    "    \"\"\"\r\n",
    "    example_all = []\r\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as fp:\r\n",
    "        for line in fp:\r\n",
    "            example_all.append(json.loads(line))\r\n",
    "    id2spo_path = os.path.join(os.path.dirname(file_path), \"id2spo.json\")\r\n",
    "    with open(id2spo_path, 'r', encoding='utf8') as fp:\r\n",
    "        id2spo = json.load(fp)\r\n",
    "\r\n",
    "    model.eval()\r\n",
    "    loss_all = 0\r\n",
    "    eval_steps = 0\r\n",
    "    formatted_outputs = []\r\n",
    "    current_idx = 0\r\n",
    "    for batch in tqdm(data_loader, total=len(data_loader)):\r\n",
    "        eval_steps += 1\r\n",
    "        input_ids, seq_len, tok_to_orig_start_index, tok_to_orig_end_index, labels = batch\r\n",
    "        logits = model(input_ids=input_ids)\r\n",
    "        mask = (input_ids != 0).logical_and((input_ids != 1)).logical_and((input_ids != 2))\r\n",
    "        loss = criterion(logits, labels, mask)\r\n",
    "        loss_all += loss.numpy().item()\r\n",
    "        probs = F.sigmoid(logits)\r\n",
    "        logits_batch = probs.numpy()\r\n",
    "        seq_len_batch = seq_len.numpy()\r\n",
    "        tok_to_orig_start_index_batch = tok_to_orig_start_index.numpy()\r\n",
    "        tok_to_orig_end_index_batch = tok_to_orig_end_index.numpy()\r\n",
    "        formatted_outputs.extend(decoding(example_all[current_idx: current_idx+len(logits)],\r\n",
    "                                          id2spo,\r\n",
    "                                          logits_batch,\r\n",
    "                                          seq_len_batch,\r\n",
    "                                          tok_to_orig_start_index_batch,\r\n",
    "                                          tok_to_orig_end_index_batch))\r\n",
    "        current_idx = current_idx+len(logits)\r\n",
    "    loss_avg = loss_all / eval_steps\r\n",
    "    print(\"eval loss: %f\" % (loss_avg))\r\n",
    "\r\n",
    "    if mode == \"predict\":\r\n",
    "        predict_file_path = os.path.join(\"/home/aistudio/relation_extraction/data\", 'predictions.json')\r\n",
    "    else:\r\n",
    "        predict_file_path = os.path.join(\"/home/aistudio/relation_extraction/data\", 'predict_eval.json')\r\n",
    "\r\n",
    "    predict_zipfile_path = write_prediction_results(formatted_outputs,\r\n",
    "                                                    predict_file_path)\r\n",
    "\r\n",
    "    if mode == \"eval\":\r\n",
    "        precision, recall, f1 = get_precision_recall_f1(file_path,\r\n",
    "                                                        predict_zipfile_path)\r\n",
    "        os.system('rm {} {}'.format(predict_file_path, predict_zipfile_path))\r\n",
    "        return precision, recall, f1\r\n",
    "    elif mode != \"predict\":\r\n",
    "        raise Exception(\"wrong mode for eval func\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from paddlenlp.transformers import LinearDecayWithWarmup\r\n",
    "\r\n",
    "learning_rate = 2e-5\r\n",
    "num_train_epochs = 5\r\n",
    "warmup_ratio = 0.06\r\n",
    "\r\n",
    "criterion = BCELossForDuIE()\r\n",
    "# Defines learning rate strategy.\r\n",
    "steps_by_epoch = len(train_data_loader)\r\n",
    "num_training_steps = steps_by_epoch * num_train_epochs\r\n",
    "lr_scheduler = LinearDecayWithWarmup(learning_rate, num_training_steps, warmup_ratio)\r\n",
    "optimizer = paddle.optimizer.AdamW(\r\n",
    "    learning_rate=lr_scheduler,\r\n",
    "    parameters=model.parameters(),\r\n",
    "    apply_decay_param_fun=lambda x: x in [\r\n",
    "        p.name for n, p in model.named_parameters()\r\n",
    "        if not any(nd in n for nd in [\"bias\", \"norm\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘checkpoints’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "# 模型参数保存路径\r\n",
    "!mkdir checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====start training of 0 epochs=====\n",
      "epoch: 0 / 2, steps: 0 / 5352, loss: 0.741553, speed: 35.18 step/s\n",
      "epoch: 0 / 2, steps: 50 / 5352, loss: 0.712035, speed: 1.05 step/s\n",
      "epoch: 0 / 2, steps: 100 / 5352, loss: 0.609313, speed: 1.06 step/s\n",
      "epoch: 0 / 2, steps: 150 / 5352, loss: 0.276713, speed: 1.10 step/s\n",
      "epoch: 0 / 2, steps: 200 / 5352, loss: 0.181118, speed: 1.10 step/s\n"
     ]
    }
   ],
   "source": [
    "import time\r\n",
    "import paddle.nn.functional as F\r\n",
    "\r\n",
    "# Starts training.\r\n",
    "global_step = 0\r\n",
    "logging_steps = 50\r\n",
    "save_steps = 10000\r\n",
    "num_train_epochs = 2\r\n",
    "output_dir = 'checkpoints_albert'\r\n",
    "tic_train = time.time()\r\n",
    "model.train()\r\n",
    "for epoch in range(num_train_epochs):\r\n",
    "    print(\"\\n=====start training of %d epochs=====\" % epoch)\r\n",
    "    tic_epoch = time.time()\r\n",
    "    for step, batch in enumerate(train_data_loader):\r\n",
    "        input_ids, seq_lens, tok_to_orig_start_index, tok_to_orig_end_index, labels = batch\r\n",
    "        logits = model(input_ids=input_ids)\r\n",
    "        mask = (input_ids != 0).logical_and((input_ids != 1)).logical_and(\r\n",
    "            (input_ids != 2))\r\n",
    "        loss = criterion(logits, labels, mask)\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "        lr_scheduler.step()\r\n",
    "        optimizer.clear_gradients()\r\n",
    "        loss_item = loss.numpy().item()\r\n",
    "\r\n",
    "        if global_step % logging_steps == 0:\r\n",
    "            print(\r\n",
    "                \"epoch: %d / %d, steps: %d / %d, loss: %f, speed: %.2f step/s\"\r\n",
    "                % (epoch, num_train_epochs, step, steps_by_epoch,\r\n",
    "                    loss_item, logging_steps / (time.time() - tic_train)))\r\n",
    "            tic_train = time.time()\r\n",
    "\r\n",
    "        if global_step % save_steps == 0 and global_step != 0:\r\n",
    "            print(\"\\n=====start evaluating ckpt of %d steps=====\" %\r\n",
    "                    global_step)\r\n",
    "            precision, recall, f1 = evaluate(\r\n",
    "                model, criterion, test_data_loader, eval_file_path, \"eval\")\r\n",
    "            print(\"precision: %.2f\\t recall: %.2f\\t f1: %.2f\\t\" %\r\n",
    "                    (100 * precision, 100 * recall, 100 * f1))\r\n",
    "            print(\"saving checkpoing model_%d.pdparams to %s \" %\r\n",
    "                    (global_step, output_dir))\r\n",
    "            paddle.save(model.state_dict(),\r\n",
    "                        os.path.join(output_dir, \r\n",
    "                                        \"model_%d.pdparams\" % global_step))\r\n",
    "            model.train()\r\n",
    "\r\n",
    "        global_step += 1\r\n",
    "    tic_epoch = time.time() - tic_epoch\r\n",
    "    print(\"epoch time footprint: %d hour %d min %d sec\" %\r\n",
    "            (tic_epoch // 3600, (tic_epoch % 3600) // 60, tic_epoch % 60))\r\n",
    "\r\n",
    "# Does final evaluation.\r\n",
    "print(\"\\n=====start evaluating last ckpt of %d steps=====\" %\r\n",
    "        global_step)\r\n",
    "precision, recall, f1 = evaluate(model, criterion, test_data_loader,\r\n",
    "                                    eval_file_path, \"eval\")\r\n",
    "print(\"precision: %.2f\\t recall: %.2f\\t f1: %.2f\\t\" %\r\n",
    "        (100 * precision, 100 * recall, 100 * f1))\r\n",
    "paddle.save(model.state_dict(),\r\n",
    "            os.path.join(output_dir,\r\n",
    "                            \"model_%d.pdparams\" % global_step))\r\n",
    "print(\"\\n=====training complete=====\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# !bash predict.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 模型集成\n",
    "\n",
    "使用多个模型进行训练预测，将各个模型预测结果进行融合。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "以上基线实现基于PaddleNLP，开源不易，希望大家多多支持~ \n",
    "**记得给[PaddleNLP](https://github.com/PaddlePaddle/PaddleNLP)点个小小的Star⭐，及时跟踪最新消息和功能哦**\n",
    "\n",
    "GitHub地址：[https://github.com/PaddlePaddle/PaddleNLP](https://github.com/PaddlePaddle/PaddleNLP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.1.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
